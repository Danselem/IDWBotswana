{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import librosa as lb\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from  more_itertools import unique_everseen\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main flow of this code is further down the notebook. It requires a number of pre-defined functions and we could have saved all of these into a library and imported them, but just to be explicit they're presented here.\n",
    "\n",
    "First up, we'll need a function to split a song up into time chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to split up a song into TIME chunks\n",
    "def splitT(mint,maxt,songdat):\n",
    "    splittime=[]\n",
    "    for i in range(mint,maxt):\n",
    "        splittime.append(songdat[:,i]) # first axis is freq, second axis is time. Return all freq for specific time range.\n",
    "    return (np.array(splittime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and we'll need a function to split a song up into frequency chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to split up a song into FREQ chunks\n",
    "def splitF(minv, maxv, songdat):\n",
    "    splitfreq = []\n",
    "    for i in range(minv,maxv):\n",
    "        splitfreq.append(songdat[i,:]) # first axis is freq, second axis is time. Return all time for specific freq range.\n",
    "    #print(splitfreq)\n",
    "    return (np.array(splitfreq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a master function to extract the machine learning features. This is the main function which gets features from the songs. Most values returned are the mean of the whole time series, hence '_a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_mean(song,sr,hop_length,n_fft):\n",
    "    try:\n",
    "        print('>>> extracting features...')\n",
    "        y_harmonic, y_percussive = lb.effects.hpss(song) #split song into harmonic and percussive parts\n",
    "        stft_harmonic=lb.core.stft(y_harmonic, n_fft=n_fft, hop_length=hop_length)\t#Compute power spectrogram.\n",
    "        stft_percussive=lb.core.stft(y_percussive, n_fft=n_fft, hop_length=hop_length)\t#Compute power spectrogram.\n",
    "        #stft_all=lb.core.stft(song, n_fft=n_fft, hop_length=hop_length)\t#Compute power spectrogram.\n",
    "        band_resolution=[5] #[5,25] Choose number of bands, do low and high resolution?\n",
    "        bands_dict=OrderedDict()\n",
    "        \n",
    "        for no_bands in band_resolution:\n",
    "            bands=np.logspace(1.3,4,no_bands)/10 #note that as n_fft is 2050 (I've decided this is sensible resolution), bands/10=freq\n",
    "            bands_int=bands.astype(int)\n",
    "            bands_int_unique=list(unique_everseen(bands_int)) #removing double entries less than 100Hz, because logspace bunches up down there and we don't need doubles when rounding to the nearest 10 Hz.\n",
    "            \n",
    "            for i in range(0,len(bands_int_unique)-1):\n",
    "                \n",
    "                _h=lb.feature.rmse(y=(splitF(bands_int_unique[i],bands_int_unique[i+1],stft_harmonic)))\n",
    "                _p=lb.feature.rmse(y=(splitF(bands_int_unique[i],bands_int_unique[i+1],stft_percussive)))\n",
    "                \n",
    "                #Calculate statistics for harmoinc and percussive over the time series.\n",
    "                rms_h=np.mean(np.abs(_h))\n",
    "                std_h=np.std(np.abs(_h))\n",
    "                skew_h=skew(np.mean(np.abs(_h), axis=0))  #skew of the time series (avg along freq axis, axis=0)\n",
    "                kurtosis_h=kurtosis(np.mean(np.abs(_h), axis=0), fisher=True, bias=True) #kurtosis of time series (avg along freq axis=0)\n",
    "                \n",
    "                rms_p=np.mean(np.abs(_p))\n",
    "                std_p=np.std(np.abs(_p))\n",
    "                skew_p=skew(np.mean(np.abs(_p), axis=0))  #skew of the time series (avg along freq axis, axis=0)\n",
    "                kurtosis_p=kurtosis(np.mean(np.abs(_p), axis=0), fisher=True, bias=True) #kurtosis of time series (avg along freq axis=0)\n",
    "\n",
    "                #Append results to dict, with numbers as band labels\n",
    "                bands_dict.update({'{0}band_rms_h{1}'.format(no_bands,i):rms_h,'{0}band_rms_p{1}'.format(no_bands,i):rms_p})\n",
    "                bands_dict.update({'{0}band_std_h{1}'.format(no_bands,i):std_h,'{0}band_std_p{1}'.format(no_bands,i):std_p})\n",
    "                bands_dict.update({'{0}band_skew_h{1}'.format(no_bands,i):skew_h,'{0}band_skew_p{1}'.format(no_bands,i):skew_p})\n",
    "                bands_dict.update({'{0}band_kurtosis_h{1}'.format(no_bands,i):kurtosis_h,'{0}band_kurtosis_p{1}'.format(no_bands,i):kurtosis_p})\n",
    "\n",
    "        #stft=lb.feature.chroma_stft(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute a chromagram from a waveform or power spectrogram.\n",
    "        #stft_a=np.mean(stft[0])\n",
    "        #stft_std=np.std(stft[0])\n",
    "        #rmse=lb.feature.rmse(y=song)\t#Compute root-mean-square (RMS) energy for each frame, either from the audio samples y or from a spectrogram S.\n",
    "        #rmse_a=np.mean(rmse)\n",
    "        #rmse_std=np.std(rmse)\n",
    "        rmseH=np.abs(lb.feature.rmse(y=stft_harmonic))\t#Compute root-mean-square (RMS) energy for harmonic\n",
    "        rmseH_a=np.mean(rmseH)\n",
    "        rmseH_std=np.std(rmseH)\n",
    "        rmseH_skew=skew(np.mean(rmseH, axis=0))\n",
    "        rmseH_kurtosis=kurtosis(np.mean(rmseH, axis=0), fisher=True, bias=True)\n",
    "\n",
    "        rmseP=np.abs(lb.feature.rmse(y=stft_percussive))\t#Compute root-mean-square (RMS) energy for percussive\n",
    "        rmseP_a=np.mean(rmseP)\n",
    "        rmseP_std=np.std(rmseP)\n",
    "        rmseP_skew=skew(np.mean(rmseP, axis=0))\n",
    "        rmseP_kurtosis=kurtosis(np.mean(rmseP, axis=0), fisher=True, bias=True)\n",
    "\n",
    "        centroid=lb.feature.spectral_centroid(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute the spectral centroid.\n",
    "        centroid_a=np.mean(centroid)\n",
    "        centroid_std=np.std(centroid)\n",
    "        bw=lb.feature.spectral_bandwidth(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute pâ€™th-order spectral bandwidth:\n",
    "        bw_a=np.mean(bw)\n",
    "        bw_std=np.std(bw)\n",
    "        contrast=lb.feature.spectral_contrast(song, sr, n_fft=n_fft, hop_length=hop_length)\t#Compute spectral contrast [R16]\n",
    "        contrast_a=np.mean(contrast)\n",
    "        contrast_std=np.std(contrast)\n",
    "        polyfeat=lb.feature.poly_features(y_harmonic, sr, n_fft=n_fft, hop_length=hop_length)\t#Get coefficients of fitting an nth-order polynomial to the columns of a spectrogram.\n",
    "        polyfeat_a=np.mean(polyfeat[0])\n",
    "        polyfeat_std=np.std(polyfeat[0])\n",
    "        tonnetz=lb.feature.tonnetz(librosa.effects.harmonic(y_harmonic), sr)\t#Computes the tonal centroid features (tonnetz), following the method of [R17].\n",
    "        tonnetz_a=np.mean(tonnetz)\n",
    "        tonnetz_std=np.std(tonnetz)\n",
    "        zcr=lb.feature.zero_crossing_rate(song, sr, hop_length=hop_length)  #zero crossing rate\n",
    "        zcr_a=np.mean(zcr)\n",
    "        zcr_std=np.std(zcr)\n",
    "        onset_env=lb.onset.onset_strength(y_percussive, sr=sr)\n",
    "        onset_a=np.mean(onset_env)\n",
    "        onset_std=np.std(onset_env)\n",
    "        D = librosa.stft(song)\n",
    "        times = librosa.frames_to_time(np.arange(D.shape[1])) #not returned, but could be if you want to plot things as a time series\n",
    "        bpm,beats=lb.beat.beat_track(y=y_percussive, sr=sr, onset_envelope=onset_env, units='time')\n",
    "        beats_a=np.mean(beats)\n",
    "        beats_std=np.std(beats)\n",
    "\n",
    "        features_dict=OrderedDict({'rmseP_a':rmseP_a,'rmseP_std':rmseP_std,'rmseH_a':rmseH_a,'rmseH_std':rmseH_std,'centroid_a':centroid_a,'centroid_std':centroid_std,'bw_a':bw_a,'bw_std':bw_std,'contrast_a':contrast_a,'contrast_std':contrast_std,'polyfeat_a':polyfeat_a,'polyfeat_std':polyfeat_std,'tonnetz_a':tonnetz_a,'tonnetz_std':tonnetz_std,'zcr_a':zcr_a,'zcr_std':zcr_std,'onset_a':onset_a,'onset_std':onset_std,'bpm':bpm, 'rmseP_skew':rmseP_skew, 'rmseP_kurtosis':rmseP_kurtosis, 'rmseH_skew':rmseH_skew, 'rmseH_kurtosis':rmseH_kurtosis})\n",
    "        combine_features={**features_dict,**bands_dict}\n",
    "        print('>>> features extracted successfully')\n",
    "        return combine_features\n",
    "\n",
    "    except:\n",
    "        print('.'*20+'FAILED'+'.'*20)\n",
    "        print('.'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a function to load the songs into python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load music function, accepts any format i've encountered: mp3,wav,wma bla bla\n",
    "def load_music(songname1,songpath1):\n",
    "    try:\n",
    "        print('loading the song: {0} ......... located here: {1} '.format(songname1, songpath1))\n",
    "        songdata1, sr1 = lb.load(songpath1) # librosa library used to grab song data and sample rate\n",
    "        print ('done........ '+songname1)\n",
    "        return [songname1,songdata1,sr1]\n",
    "    except: # the song could be corrupt or you could be trying to load something which isn't a song\n",
    "        print('..............................FAILED...............................')\n",
    "        print(songpath1)\n",
    "        print('...................................................................')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for saving the python dictionaries to disk\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading the python dictionaries from disk\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want a grid-plot to test anything out, this will help. \n",
    "# Although I've made sure get_features returns only averaged values, not time-series data, so meh.\n",
    "def gridplot(data_dict,feature,size,N,ind):\n",
    "    f, axarr = plt.subplots(size, size, sharey=True)\n",
    "    i=0\n",
    "    j=0\n",
    "    for key in data_dict:\n",
    "        #print (i,j)\n",
    "        axarr[i,j].plot(np.convolve(data_dict[key][feature][ind],np.ones((N,))/N, mode='valid'))\n",
    "        axarr[i, j].set_title(key[:3])\n",
    "        if j==size-1: i+=1\n",
    "        j=0 if j==size-1 else j+1\n",
    "    for i in range(1,size,1):\n",
    "        plt.setp([a.get_yticklabels() for a in axarr[:, i]], visible=False)\n",
    "    plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "This is where we actually start to write the main program...\n",
    "\n",
    "Let's make a note of the start time for loading our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_load=time.time() # we're going to want know how long this takes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a computationally expensive routine so we should use multiprocessing. Let's work out how many cores are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have 4 cores available to do your bidding...\n"
     ]
    }
   ],
   "source": [
    "num_workers = multiprocessing.cpu_count() \n",
    "print('you have {0} cores available to do your bidding...'.format(num_workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft1=2050 # important parameter here; this is the size of the fft window. these are sensible values\n",
    "hop_length1=441 # n_fft/5 is a sensible value. Too large and you don't sample properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a temporary database for the songs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create song database, songdb:\n",
    "songname_tmp=[]\n",
    "songpath_tmp=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is set to start reading in the song names. So we need to tell the program where to find them, i.e. the name of the artist directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='BandOfSkulls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output feature file will have the same name with the suffix \"_data\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile=str(path)+'_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the list of songs by looping through the directory contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03 I Know What I Am.m4a\n",
      "06 Patterns.m4a\n",
      "11 Cold Fame.m4a\n",
      "12 Stun Me All Wonderful.m4a\n",
      "08 Impossible.m4a\n",
      "01 Light of the Morning.m4a\n",
      "09 Blood.m4a\n",
      "05 Honest.m4a\n",
      "13 I Know What I Am (Live At the Viper Room).m4a\n",
      "10 Dull Gold Heart.m4a\n",
      "04 Fires.m4a\n",
      "07 Bomb.m4a\n",
      "02 Death By Diamonds and Pearls.m4a\n"
     ]
    }
   ],
   "source": [
    "for song in os.listdir(path):\n",
    "    print (song)\n",
    "    songname_tmp.append(song)\n",
    "    songpath_tmp.append(path+'/'+song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "songname=songname_tmp #i'm just reassigning the name incase of tests with commented out lines...\n",
    "songpath=songpath_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the song data is a slow process, so we'll parallelize it over multiple processors. A **starmap** is a way to pass multiple arguments to a single function using multiple processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> loading songs...\n",
      "loading the song: 03 I Know What I Am.m4a ......... located here: BandOfSkulls/03 I Know What I Am.m4a \n",
      "done........ 03 I Know What I Am.m4a\n",
      "loading the song: 06 Patterns.m4a ......... located here: BandOfSkulls/06 Patterns.m4a \n",
      "done........ 06 Patterns.m4a\n",
      "loading the song: 11 Cold Fame.m4a ......... located here: BandOfSkulls/11 Cold Fame.m4a \n",
      "done........ 11 Cold Fame.m4a\n",
      "loading the song: 12 Stun Me All Wonderful.m4a ......... located here: BandOfSkulls/12 Stun Me All Wonderful.m4a \n",
      "done........ 12 Stun Me All Wonderful.m4a\n",
      "loading the song: 08 Impossible.m4a ......... located here: BandOfSkulls/08 Impossible.m4a \n",
      "done........ 08 Impossible.m4a\n",
      "loading the song: 01 Light of the Morning.m4a ......... located here: BandOfSkulls/01 Light of the Morning.m4a \n",
      "done........ 01 Light of the Morning.m4a\n",
      "loading the song: 09 Blood.m4a ......... located here: BandOfSkulls/09 Blood.m4a \n",
      "done........ 09 Blood.m4a\n",
      "loading the song: 05 Honest.m4a ......... located here: BandOfSkulls/05 Honest.m4a \n",
      "done........ 05 Honest.m4a\n",
      "loading the song: 13 I Know What I Am (Live At the Viper Room).m4a ......... located here: BandOfSkulls/13 I Know What I Am (Live At the Viper Room).m4a \n",
      "done........ 13 I Know What I Am (Live At the Viper Room).m4a\n",
      "loading the song: 10 Dull Gold Heart.m4a ......... located here: BandOfSkulls/10 Dull Gold Heart.m4a \n",
      "done........ 10 Dull Gold Heart.m4a\n",
      "loading the song: 04 Fires.m4a ......... located here: BandOfSkulls/04 Fires.m4a \n",
      "done........ 04 Fires.m4a\n",
      "loading the song: 07 Bomb.m4a ......... located here: BandOfSkulls/07 Bomb.m4a \n",
      "done........ 07 Bomb.m4a\n",
      "loading the song: 02 Death By Diamonds and Pearls.m4a ......... located here: BandOfSkulls/02 Death By Diamonds and Pearls.m4a \n",
      "done........ 02 Death By Diamonds and Pearls.m4a\n",
      ">>> finished loading songs into songdb\n"
     ]
    }
   ],
   "source": [
    "print('>>> loading songs...')\n",
    "\n",
    "# =====\n",
    "# Parallel version:\n",
    "#with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "#    songdb=pool.starmap(load_music,zip(songname,songpath))\n",
    "#    pool.close()\n",
    "#    pool.join()\n",
    "\n",
    "# Serial version:\n",
    "songdb=[]\n",
    "for i in range(0, len(songname)):\n",
    "    songdb.append(load_music(songname[i], songpath[i]))\n",
    "# =====\n",
    "\n",
    "print('>>> finished loading songs into songdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a quick check to remove any entries where loading may have failed for any reason (rare cases):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> loaded 13 songs into memory\n"
     ]
    }
   ],
   "source": [
    "print ('>>> loaded {0} songs into memory'.format(len(songdb)))\n",
    "songdb=[x for x in songdb if x is not None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_name=[] # text\n",
    "song_data=[] # list of numbers\n",
    "song_sr=[]   # sample rate\n",
    "\n",
    "for song1 in songdb: \n",
    "    song_name.append(song1[0])\n",
    "    song_data.append(song1[1])\n",
    "    song_sr.append(song1[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the last step in loading the songs, so let's check how long it took:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> loading the songs into memory took 116.20213508605957 seconds\n"
     ]
    }
   ],
   "source": [
    "stop_load=time.time()\n",
    "\n",
    "loadtime = stop_load - start_load\n",
    "print('>>> loading the songs into memory took {0} seconds'.format(loadtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll extract the machine learning features from the songs, so let's make a note of our start time for this step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_feat = time.time() # note the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the features we use the **get_features_mean** function defined earlier. Again this can be slow so we're spreading it over multiple processors.\n",
    "\n",
    "**Note:** you will get a string of deprecation errors, you can safely ignore them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is all ready, now extracting features from the songs...\n",
      "extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annascaife/SRC/MUSIC/JBCA_Hack_Night_Dec/p3env/lib/python3.6/site-packages/librosa/util/utils.py:1640: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not np.issubdtype(dtype, float):\n",
      "/Users/annascaife/SRC/MUSIC/JBCA_Hack_Night_Dec/p3env/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "/Users/annascaife/SRC/MUSIC/JBCA_Hack_Night_Dec/p3env/lib/python3.6/site-packages/librosa/util/utils.py:991: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return (x > x_pad[inds1]) & (x >= x_pad[inds2])\n",
      "/Users/annascaife/SRC/MUSIC/JBCA_Hack_Night_Dec/p3env/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "/Users/annascaife/SRC/MUSIC/JBCA_Hack_Night_Dec/p3env/lib/python3.6/site-packages/librosa/core/audio.py:569: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.pad((y_sign[slice_post] != y_sign[slice_pre]),\n",
      "/Users/annascaife/SRC/MUSIC/JBCA_Hack_Night_Dec/p3env/lib/python3.6/site-packages/librosa/util/utils.py:1542: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  data_agg[idx_agg] = aggregate(data[idx_in], axis=axis)\n",
      "/Users/annascaife/SRC/MUSIC/JBCA_Hack_Night_Dec/p3env/lib/python3.6/site-packages/scipy/fftpack/basic.py:160: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  z[index] = x\n",
      "/Users/annascaife/SRC/MUSIC/JBCA_Hack_Night_Dec/p3env/lib/python3.6/site-packages/librosa/core/audio.py:442: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  autocorr = autocorr[subslice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "extracting features...\n",
      "here\n",
      "features extracted successfully\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(\">>> Data is all ready, now extracting features from the songs...\")\n",
    "\n",
    "# =====\n",
    "# Parallel version:\n",
    "#with multiprocessing.Pool(processes=num_workers,maxtasksperchild=1) as pool:\n",
    "#    res=pool.starmap(get_features_mean,zip(song_data,song_sr,itertools.repeat(hop_length1),itertools.repeat(n_fft1)))\n",
    "#    pool.close()\n",
    "#    pool.join()\n",
    "\n",
    "# Serial version:\n",
    "res=[]\n",
    "for i in range(0,len(song_data)):\n",
    "    res.append(get_features_mean(song_data[i], song_sr[i], hop_length1, n_fft1))\n",
    "\n",
    "# =====\n",
    "\n",
    "print('>>> extracted {0} features from all songs'.format(len(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've got the features we concatenate them all into a single dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> concatenating results into a massive dictionary...\n"
     ]
    }
   ],
   "source": [
    "# concatenate each songs features (res) into dictionary\n",
    "print('>>> concatenating results into a massive dictionary...')\n",
    "\n",
    "data_dict_mean={}\n",
    "for i in range(0,len(songdb)):\n",
    "    data_dict_mean.update({song_name[i]:res[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and that's it, really. Now we can just check our features and save them for use with our machine learning algorithms later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> The features extracted from the songs are: \n",
      "dict_keys(['rmseP_a', 'rmseP_std', 'rmseH_a', 'rmseH_std', 'centroid_a', 'centroid_std', 'bw_a', 'bw_std', 'contrast_a', 'contrast_std', 'polyfeat_a', 'polyfeat_std', 'tonnetz_a', 'tonnetz_std', 'zcr_a', 'zcr_std', 'onset_a', 'onset_std', 'bpm', 'rmseP_skew', 'rmseP_kurtosis', 'rmseH_skew', 'rmseH_kurtosis', '5band_rms_h0', '5band_rms_p0', '5band_std_h0', '5band_std_p0', '5band_skew_h0', '5band_skew_p0', '5band_kurtosis_h0', '5band_kurtosis_p0', '5band_rms_h1', '5band_rms_p1', '5band_std_h1', '5band_std_p1', '5band_skew_h1', '5band_skew_p1', '5band_kurtosis_h1', '5band_kurtosis_p1', '5band_rms_h2', '5band_rms_p2', '5band_std_h2', '5band_std_p2', '5band_skew_h2', '5band_skew_p2', '5band_kurtosis_h2', '5band_kurtosis_p2', '5band_rms_h3', '5band_rms_p3', '5band_std_h3', '5band_std_p3', '5band_skew_h3', '5band_skew_p3', '5band_kurtosis_h3', '5band_kurtosis_p3'])\n",
      "----------\n",
      ">>> Saving dictionary to disk...\n",
      "----------\n",
      "loading time: 116.2139482498169 seconds\n",
      "feature extraction time: 905.6102027893066 seconds\n",
      "total time: 1021.8241510391235 seconds\n",
      "----------\n",
      ">>> Finished\n"
     ]
    }
   ],
   "source": [
    "# print features to screen to check\n",
    "print('>>> The features extracted from the songs are: ')\n",
    "print(res[0].keys())\n",
    "\n",
    "print(\"----------\")\n",
    "print('>>> Saving dictionary to disk...')\n",
    "save_obj(data_dict_mean,savefile)\n",
    "\n",
    "end_feat=time.time() # note finish time\n",
    "print(\"----------\")\n",
    "print(\"loading time: {0} seconds\".format(start_feat-start_load))\n",
    "print(\"feature extraction time: {0} seconds\".format(end_feat-start_feat))\n",
    "print(\"total time: {0} seconds\".format(end_feat-start_load))\n",
    "print(\"----------\")\n",
    "print('>>> Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
